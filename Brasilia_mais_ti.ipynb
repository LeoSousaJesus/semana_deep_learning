{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmLMNKdqSyTrDz+0US8Zrf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeoSousaJesus/semana_deep_learning/blob/main/Brasilia_mais_ti.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visão Computacional com OpenCV e MediaPipe**"
      ],
      "metadata": {
        "id": "2U6HMa6Ysi41"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Esse código apresenta um sistema de detecção de rosto e análise de expressão facial para detectar se uma pessoa está com os olhos fechados por muito tempo e abrindo a boca (bocejo), indicando sonolência e possível perigo, caso esteja, tocar os sons de alerta para os dois casos."
      ],
      "metadata": {
        "id": "HWTVQqHgDStu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Distância Euclidiana (1D,2D,3D, n....)\n",
        "# Média (cálculo do EAR)"
      ],
      "metadata": {
        "id": "0IOACLIZjL02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Para rodar o programa execute o comando: python prova.py"
      ],
      "metadata": {
        "id": "wtC0qdgwDXsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Importação das bibliotecas"
      ],
      "metadata": {
        "id": "VZyLIiEtDfYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import time\n",
        "import pygame\n",
        "import os\n",
        "import sys"
      ],
      "metadata": {
        "id": "ljOSjD67Dinv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **cv2:** OpenCV para processamento de imagens e manipulação de câmera.\n",
        "- **mediapipe:** Para detecção de rosto e pontos visíveis.\n",
        "- **numpy:** Para manipulações numéricas (ex., vetores e cálculos).\n",
        "- **time:** Para controlar o tempo (ex., duração dos olhos fechados).\n",
        "- **pygame:** Para tocar arquivos de áudio como som de alerta.\n",
        "- **os e sys:** Para operações no sistema (não são usados ​​neste trecho)."
      ],
      "metadata": {
        "id": "QUTAMeb3DmGf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Inicialize o sistema de som"
      ],
      "metadata": {
        "id": "EmQSo8BgDzEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pygame.mixer.music.load(\"alarmenavio.mp3\")  # Alarme da boca\n",
        "som_olho = pygame.mixer.Sound(\"businadj.mp3\")  # Alarme dos olhos\n",
        "som_assobio = pygame.mixer.Sound(\"assobio.mp3\")  # Som para rosto detectado"
      ],
      "metadata": {
        "id": "QiNLWhNID0aA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **pygame.mixer.init():** Inicializa o sistema de som do Pygame.\n",
        "- **pygame.mixer.music.load(\"sonscerrado.mp3\"):** Carrega o arquivo de som que será reproduzido quando necessário."
      ],
      "metadata": {
        "id": "KPeVcpODD2rK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Definindo pontos dos olhos e boca"
      ],
      "metadata": {
        "id": "0jDtURtSD8Jh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p_olho_esq = [385, 380, 387, 373, 362, 263]\n",
        "p_olho_dir = [160, 144, 158, 153, 33, 133]\n",
        "p_olhos = p_olho_esq + p_olho_dir\n",
        "p_boca = [82, 87, 13, 14, 312, 317, 78, 308]"
      ],
      "metadata": {
        "id": "Lno9D1K2EAPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Essas listas armazenam os índices dos pontos específicos da face que representam os olhos e a boca. Esses índices são usados ​​para calcular as métricas de abertura e fechamento dos olhos e boca."
      ],
      "metadata": {
        "id": "gVavtrGwECop"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Função EAR (Eye Aspect Ratio) Proporção do Olho"
      ],
      "metadata": {
        "id": "j-IWM_aCEGgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculo_ear(face, p_olho_dir, p_olho_esq):\n",
        "    try:\n",
        "        face = np.array([[coord.x, coord.y] for coord in face])\n",
        "        face_esq = face[p_olho_esq, :]\n",
        "        face_dir = face[p_olho_dir, :]\n",
        "\n",
        "        ear_esq = (np.linalg.norm(face_esq[0] - face_esq[1]) + np.linalg.norm(face_esq[2] - face_esq[3])) / (2 * (np.linalg.norm(face_esq[4] - face_esq[5])))\n",
        "        ear_dir = (np.linalg.norm(face_dir[0] - face_dir[1]) + np.linalg.norm(face_dir[2] - face_dir[3])) / (2 * (np.linalg.norm(face_dir[4] - face_dir[5])))\n",
        "    except:\n",
        "        ear_esq = 0.0\n",
        "        ear_dir = 0.0\n",
        "    media_ear = (ear_esq + ear_dir) / 2\n",
        "    return media_ear"
      ],
      "metadata": {
        "id": "ffSP9sgaELpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A função calcula o Eye Aspect Ratio (EAR), que indica o grau de abertura dos olhos:\n",
        "\n",
        "- Converte coordenadas dos pontos visíveis em matrizes.\n",
        "- Seleciona os pontos dos olhos e calcula a razão entre as distâncias verticais e horizontais (indicando se os olhos estão abertos ou internos).\n",
        "- Retorna a média dos EAR dos olhos direito e esquerdo."
      ],
      "metadata": {
        "id": "KF5nqQFkEQME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Função MAR (Mouth Aspect Ratio) Proporção de aspecto da Boca\n"
      ],
      "metadata": {
        "id": "BmFXyk0xEYYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculo_mar(face, p_boca):\n",
        "    try:\n",
        "        face = np.array([[coord.x, coord.y] for coord in face])\n",
        "        face_boca = face[p_boca, :]\n",
        "\n",
        "        mar = (np.linalg.norm(face_boca[0] - face_boca[1]) + np.linalg.norm(face_boca[2] - face_boca[3]) + np.linalg.norm(face_boca[4] - face_boca[5])) / (2 * (np.linalg.norm(face_boca[6] - face_boca[7])))\n",
        "    except:\n",
        "        mar = 0.0\n",
        "    return mar"
      ],
      "metadata": {
        "id": "ajDxIZJiEcKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A função calcula o Mouth Aspect Ratio (MAR), diminuindo o grau de abertura da boca (ex., bocejo):\n",
        "\n",
        "- Semelhante ao EAR, mas calcula a relação usando pontos da boca."
      ],
      "metadata": {
        "id": "YI6989zXEfpW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Limiares e controle de sono"
      ],
      "metadata": {
        "id": "s-_848RKE8SY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ear_limiar = 0.27\n",
        "mar_limiar = 0.5\n",
        "dormindo = False  # Flag para controle dos olhos fechados\n",
        "aberto_boca = False  # Flag para controle da boca aberta\n",
        "tempo_olhos_fechados = 0.0  # Tempo que os olhos ficaram fechados\n",
        "tempo_boca_aberta = 0.0  # Tempo que a boca ficou aberta\n",
        "contagem_piscadas = 0  # Contagem de piscadas"
      ],
      "metadata": {
        "id": "YoZ1Tb53E-Ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Defina os valores de limites para os EAR e MAR, e uma variável dormindo para monitorar o estado de sono (1 para dormir e 0 para acordar)."
      ],
      "metadata": {
        "id": "-8TV0zXDE_OB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Inicialização da câmera"
      ],
      "metadata": {
        "id": "OUrbv0XbFFYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(0)"
      ],
      "metadata": {
        "id": "LxzqJ1PWFGdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Ative a câmera para capturar imagens ao vivo."
      ],
      "metadata": {
        "id": "7IrMhHCDFIUC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Configuração do MediaPipe e variáveis ​​de estado e controle de exibição das mensagens"
      ],
      "metadata": {
        "id": "RoQMq5lTFMW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "\n",
        "# Estado do som\n",
        "som_boca_tocando = False\n",
        "som_olho_tocando = False\n",
        "som_assobio_tocando = False\n",
        "\n",
        "# Variáveis para controle de exibição das mensagens\n",
        "mensagem_boca = \"\"\n",
        "mensagem_olhos = \"\"\n",
        "tempo_inicio_mensagem_boca = None\n",
        "tempo_inicio_mensagem_olhos = None\n",
        "duracao_mensagem = 3  # Duração das mensagens em segundos"
      ],
      "metadata": {
        "id": "w0CBNrREFPWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Inicialize as ferramentas de desenho e detecção de malha facial do MediaPipe. Define som_tocando para controlar o estado do som e também a exbição das mensagens de alerta."
      ],
      "metadata": {
        "id": "RnutiW-hFSlL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Configuração da janela da câmera"
      ],
      "metadata": {
        "id": "CLvRHorEFhFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "window_width = 800\n",
        "window_height = 600\n",
        "cv2.namedWindow('Camera', cv2.WINDOW_NORMAL)\n",
        "cv2.resizeWindow('Camera', window_width, window_height)"
      ],
      "metadata": {
        "id": "MSryAMncFiQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Defina uma janela de exibição da câmera com dimensões específicas."
      ],
      "metadata": {
        "id": "z50cSx1AFkjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Variáveis de tempo para o aviso de rosto\n",
        "rosto_detectado = False\n",
        "tempo_inicial_aviso = None"
      ],
      "metadata": {
        "id": "2cB65BlaU0sG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*  Definindo o aviso de rosto detectado\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oknzOSXcTPQE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Loop de captura e processamento de imagem"
      ],
      "metadata": {
        "id": "aTAGMpoyFouN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5) as facemesh:\n",
        "    while cap.isOpened():\n",
        "        sucesso, frame = cap.read()\n",
        "        if not sucesso:\n",
        "            print('Ignorando o frame vazio da câmera.')\n",
        "            continue"
      ],
      "metadata": {
        "id": "xQlNVL-hFrQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Configure o FaceMesh MediaPipe para detectar pontos visíveis. O loop principal lê frames da câmera e continua enquanto ela estiver aberta.\n"
      ],
      "metadata": {
        "id": "FxhTWke9Fuk-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. Processamento de rosto detectado"
      ],
      "metadata": {
        "id": "yQzqXozmFxmv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "        comprimento, largura, _ = frame.shape\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        saida_facemesh = facemesh.process(frame)\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)"
      ],
      "metadata": {
        "id": "PqpMvFK-F0In"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Converta uma imagem para RGB, processe como o FaceMesh e converta de volta para BGR para exibir na janela."
      ],
      "metadata": {
        "id": "Qow2TqN5F5ZY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12. Controle de reprodução de som para o rosto detectado, onde o alarme aciona quando um rosto for detectado na tela"
      ],
      "metadata": {
        "id": "4J-Ip4l9F9AB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "        if saida_facemesh.multi_face_landmarks:\n",
        "            rosto_detectado = True\n",
        "            tempo_inicial_aviso = time.time()"
      ],
      "metadata": {
        "id": "wCsTSDpSGE-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Verifique se algum rosto foi detectado. Caso positivo, toque o som (e mantenha tocando) enquanto o rosto estiver visível. Se o rosto não for detectado, o som para."
      ],
      "metadata": {
        "id": "xy2BGKkpGXOT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13. Desenho de pontos e cálculo EAR/MAR"
      ],
      "metadata": {
        "id": "OE8GTXZ1GaLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "        for face_landmarks in saida_facemesh.multi_face_landmarks:\n",
        "                mp_drawing.draw_landmarks(\n",
        "                    frame,\n",
        "                    face_landmarks,\n",
        "                    mp_face_mesh.FACEMESH_CONTOURS,\n",
        "                    landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 0, 220), thickness=1, circle_radius=1),\n",
        "                    connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 204, 0), thickness=1, circle_radius=1)\n",
        "                )\n",
        "\n",
        "                face = face_landmarks.landmark\n",
        "\n",
        "                ear = calculo_ear(face, p_olho_dir, p_olho_esq)\n",
        "                mar = calculo_mar(face, p_boca)\n",
        "                cv2.rectangle(frame,(0,1),(290,140),(58,58,55),-1)"
      ],
      "metadata": {
        "id": "svKhQ91-Gcfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Desenha pontos postais e calcula EAR e MAR, exibindo os valores no frame da câmera.\n"
      ],
      "metadata": {
        "id": "9_jjMN4pGl61"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 14. Lógica para estado de sono"
      ],
      "metadata": {
        "id": "j_kez-eAGnmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "             # Verificação da condição da boca aberta\n",
        "                if mar > mar_limiar:\n",
        "                    if not aberto_boca:\n",
        "                        tempo_inicial_boca_aberta = time.time()\n",
        "                        aberto_boca = True\n",
        "                    else:\n",
        "                        tempo_boca_aberta = time.time() - tempo_inicial_boca_aberta\n",
        "                    estado_boca = \"aberta\"\n",
        "                else:\n",
        "                    tempo_boca_aberta = 0.0\n",
        "                    aberto_boca = False\n",
        "                    estado_boca = \"fechada\"\n",
        "\n",
        "                # Verificação da condição dos olhos fechados\n",
        "                if ear < ear_limiar:\n",
        "                    if not dormindo:\n",
        "                        tempo_inicial_olhos_fechados = time.time()\n",
        "                        dormindo = True\n",
        "                    else:\n",
        "                        tempo_olhos_fechados = time.time() - tempo_inicial_olhos_fechados\n",
        "                    estado_olho = \"fechados\"\n",
        "                else:\n",
        "                    if dormindo:\n",
        "                        contagem_piscadas += 1\n",
        "                    tempo_olhos_fechados = 0.0\n",
        "                    dormindo = False\n",
        "                    estado_olho = \"abertos\""
      ],
      "metadata": {
        "id": "dEadRDaLGqoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Verifica o tempo em que os olhos ficam fechados e a boca fica aberta, alertando na tela se o tempo ultrapassar os limiares. Adiciona a contagem das piscadas para toda vez que um rosto for detectado."
      ],
      "metadata": {
        "id": "h-vrSf5TGyle"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 15. Exibição dos estados e tempos na tela"
      ],
      "metadata": {
        "id": "tQ7NqYj6G05m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "      cv2.rectangle(frame, (0, 0), (320, 80), (58, 58, 55), -1)  # Fundo do quadro\n",
        "      cv2.putText(frame, f\"MAR Boca: {estado_boca} - {round(tempo_boca_aberta, 2)}s\",\n",
        "            (10, 30), cv2.FONT_HERSHEY_TRIPLEX, 0.6, (255, 255, 255), 1)\n",
        "      cv2.putText(frame, f\"EAR Olhos: {estado_olho} - {round(tempo_olhos_fechados, 2)}s\",\n",
        "            (10, 60), cv2.FONT_HERSHEY_TRIPLEX, 0.6, (255, 255, 255), 1)\n",
        "      cv2.putText(frame, f\"Piscadas: {contagem_piscadas}\",\n",
        "            (10, 90), cv2.FONT_HERSHEY_TRIPLEX, 0.6, (255, 255, 255), 1)\n"
      ],
      "metadata": {
        "id": "-hM0Bs8TG2PW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Exibe as informações de estados (aberto ou fechado) e tempos de duração dos olhos e boca na tela da câmera. desenhamos retângulos para o fundo e os textos são exibidos com informações sobre o estado da boca (aberta/fechada), tempo que a boca ficou aberta, estado dos olhos (abertos/fechados), tempo que os olhos ficaram fechados e a contagem de piscadas."
      ],
      "metadata": {
        "id": "JP6AUL6GG7u_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 16. Alarme para boca aberta"
      ],
      "metadata": {
        "id": "vblcUBrYZbTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "        if tempo_boca_aberta >= 1.5 and not som_boca_tocando:\n",
        "            mensagem_boca = f\"Alerta de sono, bocejando!\"\n",
        "            tempo_inicio_mensagem_boca = time.time()\n",
        "            pygame.mixer.music.play(-1)\n",
        "            som_boca_tocando = True\n",
        "        elif tempo_boca_aberta == 0.0 and som_boca_tocando:\n",
        "            pygame.mixer.music.stop()\n",
        "            som_boca_tocando = False"
      ],
      "metadata": {
        "id": "6uKiZP2FZlIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Verifica se a boca está aberta por mais de 1.5 segundos. Se estiver, toca um som de alarme e exibe uma mensagem na tela. Quando a boca é fechada, o som para."
      ],
      "metadata": {
        "id": "OYn6go8ZZ2zO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 17. Alarme para olhos fechados"
      ],
      "metadata": {
        "id": "_dVhy-5IZ_ZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "            if tempo_olhos_fechados >= 1.0 and not som_olho_tocando:\n",
        "                mensagem_olhos = \"Olhos fechados por muito tempo!\"\n",
        "                tempo_inicio_mensagem_olhos = time.time()\n",
        "                som_olho.play()\n",
        "                som_olho_tocando = True\n",
        "            elif tempo_olhos_fechados == 0.0 and som_olho_tocando:\n",
        "                som_olho.stop()\n",
        "                som_olho_tocando = False\n"
      ],
      "metadata": {
        "id": "C_XwcgHoaF6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Verifica se os olhos estão fechados por mais de 1 segundo. Se estiverem, toca um som de alarme e exibe uma mensagem na tela. Quando os olhos são abertos, o som para."
      ],
      "metadata": {
        "id": "OYKVDhpQaHvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 18. Exibir mensagens no canto inferior da tela"
      ],
      "metadata": {
        "id": "ZHUokZJKapKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "              altura, largura, _ = frame.shape\n",
        "              if mensagem_boca and (time.time() - tempo_inicio_mensagem_boca <= duracao_mensagem):\n",
        "                  cv2.rectangle(frame, (0, altura - 70), (largura, altura), (0, 0, 0), -1)  # Fundo preto\n",
        "                  cv2.putText(frame, mensagem_boca, (10, altura - 30), cv2.FONT_HERSHEY_DUPLEX, 0.9, (255, 255, 255), 2)\n",
        "              else:\n",
        "                  mensagem_boca = \"\"  # Limpa a mensagem após a duração\n",
        "\n",
        "              if mensagem_olhos and (time.time() - tempo_inicio_mensagem_olhos <= duracao_mensagem):\n",
        "                  cv2.rectangle(frame, (0, altura - 140), (largura, altura - 70), (0, 0, 0), -1)  # Fundo preto\n",
        "                  cv2.putText(frame, mensagem_olhos, (10, altura - 100), cv2.FONT_HERSHEY_DUPLEX, 0.9, (255, 255, 255), 2)\n",
        "              else:\n",
        "                  mensagem_olhos = \"\"  # Limpa a mensagem após a duração\n"
      ],
      "metadata": {
        "id": "RAyKpFI6a_ZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Exibe mensagens sobre a condição da boca e olhos no canto inferior da tela. As mensagens são exibidas por um tempo determinado (duracao_mensagem) e depois são limpas."
      ],
      "metadata": {
        "id": "2ygssP6qbLOW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 19. Atualiza o estado e tempo quando nenhum rosto é detectado"
      ],
      "metadata": {
        "id": "8ixPXwq7bXlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "              if rosto_detectado:\n",
        "                  contagem_piscadas = 0  # Reinicia a contagem de piscadas quando nenhum rosto é detectado\n",
        "                  tempo_inicial_aviso = time.time()\n",
        "              rosto_detectado = False"
      ],
      "metadata": {
        "id": "dPJwFWqAbg2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- reinicia a contagem de piscadas quando nenhum rosto é detectado e atualiza o tempo de início do aviso."
      ],
      "metadata": {
        "id": "I_zFRS2ZblQx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 20. Exibe aviso de rosto detectado ou não detectado no canto superior direito"
      ],
      "metadata": {
        "id": "mdC6kMZtbtAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "              if tempo_inicial_aviso and (time.time() - tempo_inicial_aviso <= 5):\n",
        "                  mensagem = \"Rosto detectado\" if rosto_detectado else \"Nenhum rosto detectado\"\n",
        "                  cor_texto = (0, 255, 0) if rosto_detectado else (0, 0, 255)  # Verde para detectado, vermelho para não detectado\n",
        "                  largura_frame = frame.shape[1]\n",
        "                  tamanho_texto = cv2.getTextSize(mensagem, cv2.FONT_HERSHEY_DUPLEX, 1.0, 2)[0]  # Obtém o tamanho do texto\n",
        "                  posicao_x = largura_frame - tamanho_texto[0] - 10  # Calcula a posição x do texto para o canto direito\n",
        "                  posicao_y = 30  # Altura fixa no canto superior\n",
        "                  cv2.putText(frame, mensagem, (posicao_x, posicao_y), cv2.FONT_HERSHEY_DUPLEX, 1.0, cor_texto, 2)\n",
        "\n",
        "                  # Tocar som de assobio quando rosto detectado\n",
        "                  if rosto_detectado and not som_assobio_tocando:\n",
        "                      som_assobio.play()\n",
        "                      som_assobio_tocando = True\n",
        "              else:\n",
        "                  # Para o som quando o tempo de exibição da mensagem acaba\n",
        "                  if som_assobio_tocando:\n",
        "                      som_assobio.stop()\n",
        "                      som_assobio_tocando = False"
      ],
      "metadata": {
        "id": "36jgnGBBb9vT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- exibe um aviso no canto superior direito indicando se um rosto foi detectado ou não. Se um rosto é detectado, toca um som de assobio. Se não, para o som."
      ],
      "metadata": {
        "id": "f4ZmRVxzcDX1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 21. Exibir o frame da câmera e verificar a tecla de saída"
      ],
      "metadata": {
        "id": "FXDOd9_WcK-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.imshow('Camera', frame)\n",
        "if cv2.waitKey(5) & 0xFF == 27:\n",
        "    break"
      ],
      "metadata": {
        "id": "iwxfwNXtcTw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- exibe o frame da câmera e verifica se a tecla \"ESC\" foi pressionada para sair do loop."
      ],
      "metadata": {
        "id": "EeezhpLhchhH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 22. Libera a câmera e fecha todas as janelas"
      ],
      "metadata": {
        "id": "zPv7k_e5cjQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "ExV1kUQLcs0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- libera a câmera e fecha todas as janelas abertas pelo OpenCV."
      ],
      "metadata": {
        "id": "w_ikw8Hxcuw5"
      }
    }
  ]
}