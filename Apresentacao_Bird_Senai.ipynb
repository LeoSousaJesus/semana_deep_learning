{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
<<<<<<< HEAD
      "authorship_tag": "ABX9TyO3ooDdH8/UtG+uQ/WhDA0v",
=======
      "authorship_tag": "ABX9TyNG5ogofIfbm0LDHv7Ypnpu",
>>>>>>> e8a8dd3 (Aulas Deep Learning SENAI)
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeoSousaJesus/semana_deep_learning/blob/main/Apresentacao_Bird_Senai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Esse código apresenta um sistema de detecção de rosto e análise de expressão facial para detectar se uma pessoa está com os olhos fechados por muito tempo (indicativo de possível perigo) e, caso esteja, tocar um som de alerta."
      ],
      "metadata": {
        "id": "HWTVQqHgDStu"
      }
    },
    {
<<<<<<< HEAD
      "cell_type": "markdown",
      "source": [
        "# Distância Euclidiana (1D,2D,3D, n....)\n",
        "# Média (cálculo do EAR)"
      ],
      "metadata": {
        "id": "0IOACLIZjL02"
      }
    },
    {
=======
>>>>>>> e8a8dd3 (Aulas Deep Learning SENAI)
      "cell_type": "code",
      "source": [
        "# Para rodar o programa execute o comando: python birdsenai.py"
      ],
      "metadata": {
        "id": "wtC0qdgwDXsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Importação das bibliotecas"
      ],
      "metadata": {
        "id": "VZyLIiEtDfYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import time\n",
        "import pygame\n",
        "import os\n",
        "import sys"
      ],
      "metadata": {
        "id": "ljOSjD67Dinv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **cv2:** OpenCV para processamento de imagens e manipulação de câmera.\n",
        "- **mediapipe:** Para detecção de rosto e pontos visíveis.\n",
        "- **numpy:** Para manipulações numéricas (ex., vetores e cálculos).\n",
        "- **time:** Para controlar o tempo (ex., duração dos olhos fechados).\n",
        "- **pygame:** Para tocar arquivos de áudio como som de alerta.\n",
        "- **os e sys:** Para operações no sistema (não são usados ​​neste trecho)."
      ],
      "metadata": {
        "id": "QUTAMeb3DmGf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Inicialize o sistema de som"
      ],
      "metadata": {
        "id": "EmQSo8BgDzEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pygame.mixer.init()\n",
        "pygame.mixer.music.load(\"sonscerrado.mp3\")"
      ],
      "metadata": {
        "id": "QiNLWhNID0aA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **pygame.mixer.init():** Inicializa o sistema de som do Pygame.\n",
        "- **pygame.mixer.music.load(\"sonscerrado.mp3\"):** Carrega o arquivo de som que será reproduzido quando necessário."
      ],
      "metadata": {
        "id": "KPeVcpODD2rK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Definindo pontos dos olhos e boca"
      ],
      "metadata": {
        "id": "0jDtURtSD8Jh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p_olho_esq = [385, 380, 387, 373, 362, 263]\n",
        "p_olho_dir = [160, 144, 158, 153, 33, 133]\n",
        "p_olhos = p_olho_esq + p_olho_dir\n",
        "p_boca = [82, 87, 13, 14, 312, 317, 78, 308]"
      ],
      "metadata": {
        "id": "Lno9D1K2EAPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Essas listas armazenam os índices dos pontos específicos da face que representam os olhos e a boca. Esses índices são usados ​​para calcular as métricas de abertura e fechamento dos olhos e boca."
      ],
      "metadata": {
        "id": "gVavtrGwECop"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Função EAR (Proporção do Olho)"
      ],
      "metadata": {
        "id": "j-IWM_aCEGgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculo_ear(face, p_olho_dir, p_olho_esq):\n",
        "    try:\n",
        "        face = np.array([[coord.x, coord.y] for coord in face])\n",
        "        face_esq = face[p_olho_esq, :]\n",
        "        face_dir = face[p_olho_dir, :]\n",
        "\n",
        "        ear_esq = (np.linalg.norm(face_esq[0] - face_esq[1]) + np.linalg.norm(face_esq[2] - face_esq[3])) / (2 * (np.linalg.norm(face_esq[4] - face_esq[5])))\n",
        "        ear_dir = (np.linalg.norm(face_dir[0] - face_dir[1]) + np.linalg.norm(face_dir[2] - face_dir[3])) / (2 * (np.linalg.norm(face_dir[4] - face_dir[5])))\n",
        "    except:\n",
        "        ear_esq = 0.0\n",
        "        ear_dir = 0.0\n",
        "    media_ear = (ear_esq + ear_dir) / 2\n",
        "    return media_ear"
      ],
      "metadata": {
        "id": "ffSP9sgaELpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A função calcula o Eye Aspect Ratio (EAR), que indica o grau de abertura dos olhos:\n",
        "\n",
        "- Converte coordenadas dos pontos visíveis em matrizes.\n",
        "- Seleciona os pontos dos olhos e calcula a razão entre as distâncias verticais e horizontais (indicando se os olhos estão abertos ou internos).\n",
        "- Retorna a média dos EAR dos olhos direito e esquerdo."
      ],
      "metadata": {
        "id": "KF5nqQFkEQME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Função MAR (Proporção de Aspecto da Boca)\n"
      ],
      "metadata": {
        "id": "BmFXyk0xEYYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculo_mar(face, p_boca):\n",
        "    try:\n",
        "        face = np.array([[coord.x, coord.y] for coord in face])\n",
        "        face_boca = face[p_boca, :]\n",
        "\n",
        "        mar = (np.linalg.norm(face_boca[0] - face_boca[1]) + np.linalg.norm(face_boca[2] - face_boca[3]) + np.linalg.norm(face_boca[4] - face_boca[5])) / (2 * (np.linalg.norm(face_boca[6] - face_boca[7])))\n",
        "    except:\n",
        "        mar = 0.0\n",
        "    return mar"
      ],
      "metadata": {
        "id": "ajDxIZJiEcKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A função calcula o Mouth Aspect Ratio (MAR), diminuindo o grau de abertura da boca (ex., bocejo):\n",
        "\n",
        "- Semelhante ao EAR, mas calcula a relação usando pontos da boca."
      ],
      "metadata": {
        "id": "YI6989zXEfpW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Limiares e controle de sono"
      ],
      "metadata": {
        "id": "s-_848RKE8SY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ear_limiar = 0.27\n",
        "mar_limiar = 0.1\n",
        "dormindo = 0"
      ],
      "metadata": {
        "id": "YoZ1Tb53E-Ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Defina os valores de limites para os EAR e MAR, e uma variável dormindo para monitorar o estado de sono (1 para dormir e 0 para acordar)."
      ],
      "metadata": {
        "id": "-8TV0zXDE_OB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Inicialização da câmera"
      ],
      "metadata": {
        "id": "OUrbv0XbFFYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(0)"
      ],
      "metadata": {
        "id": "LxzqJ1PWFGdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Ative a câmera para capturar imagens ao vivo."
      ],
      "metadata": {
        "id": "7IrMhHCDFIUC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Configuração do MediaPipe e variáveis ​​de estado"
      ],
      "metadata": {
        "id": "RoQMq5lTFMW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "\n",
        "som_tocando = False"
      ],
      "metadata": {
        "id": "w0CBNrREFPWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Inicialize as ferramentas de desenho e detecção de malha facial do MediaPipe. Define som_tocando para controlar o estado do som."
      ],
      "metadata": {
        "id": "RnutiW-hFSlL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Configuração da janela da câmera"
      ],
      "metadata": {
        "id": "CLvRHorEFhFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "window_width = 800\n",
        "window_height = 600\n",
        "cv2.namedWindow('Camera', cv2.WINDOW_NORMAL)\n",
        "cv2.resizeWindow('Camera', window_width, window_height)"
      ],
      "metadata": {
        "id": "MSryAMncFiQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Defina uma janela de exibição da câmera com dimensões específicas."
      ],
      "metadata": {
        "id": "z50cSx1AFkjG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Loop de captura e processamento de imagem"
      ],
      "metadata": {
        "id": "aTAGMpoyFouN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5) as facemesh:\n",
        "    while cap.isOpened():\n",
        "        sucesso, frame = cap.read()\n",
        "        if not sucesso:\n",
        "            print('Ignorando o frame vazio da câmera.')\n",
        "            continue"
      ],
      "metadata": {
        "id": "xQlNVL-hFrQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Configure o FaceMesh MediaPipe para detectar pontos visíveis. O loop principal lê frames da câmera e continua enquanto ela estiver aberta.\n"
      ],
      "metadata": {
        "id": "FxhTWke9Fuk-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. Processamento de rosto detectado"
      ],
      "metadata": {
        "id": "yQzqXozmFxmv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "        comprimento, largura, _ = frame.shape\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        saida_facemesh = facemesh.process(frame)\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)"
      ],
      "metadata": {
        "id": "PqpMvFK-F0In"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Converta uma imagem para RGB, processe como o FaceMesh e converta de volta para BGR para exibir na janela."
      ],
      "metadata": {
        "id": "Qow2TqN5F5ZY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12. Controle de reprodução de som"
      ],
      "metadata": {
        "id": "4J-Ip4l9F9AB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "        if saida_facemesh.multi_face_landmarks:\n",
        "            print(\"Rosto detectado\")\n",
        "            if not som_tocando:\n",
        "                pygame.mixer.music.play(-1)\n",
        "                som_tocando = True\n",
        "        else:\n",
        "            print(\"Nenhum rosto detectado\")\n",
        "            if som_tocando:\n",
        "                pygame.mixer.music.stop()\n",
        "                som_tocando = False"
      ],
      "metadata": {
        "id": "wCsTSDpSGE-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Verifique se algum rosto foi detectado. Caso positivo, toque o som (e mantenha tocando) enquanto o rosto estiver visível. Se o rosto não for detectado, o som para."
      ],
      "metadata": {
        "id": "xy2BGKkpGXOT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13. Desenho de pontos e cálculo EAR/MAR"
      ],
      "metadata": {
        "id": "OE8GTXZ1GaLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "        for face_landmarks in saida_facemesh.multi_face_landmarks:\n",
        "            mp_drawing.draw_landmarks(frame, face_landmarks, mp_face_mesh.FACEMESH_CONTOURS)\n",
        "\n",
        "            face = face_landmarks.landmark\n",
        "            # EAR e MAR cálculos e exibição\n",
        "            ear = calculo_ear(face, p_olho_dir, p_olho_esq)\n",
        "            mar = calculo_mar(face, p_boca)\n",
        "            # Exibe os valores de EAR e MAR na tela"
      ],
      "metadata": {
        "id": "svKhQ91-Gcfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Desenha pontos postais e calcula EAR e MAR, exibindo os valores no frame da câmera.\n"
      ],
      "metadata": {
        "id": "9_jjMN4pGl61"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 14. Lógica para estado de sono"
      ],
      "metadata": {
        "id": "j_kez-eAGnmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "            if ear < ear_limiar:\n",
        "                t_inicial = time.time() if dormindo == 0 else t_inicial\n",
        "                dormindo = 1\n",
        "            if dormindo == 1 and ear >= ear_limiar:\n",
        "                dormindo = 0\n",
        "            tempo = (time.time() - t_inicial) if dormindo == 1 else 0.0\n",
        "\n",
        "            if tempo >= 1.5:\n",
        "                cv2.putText(frame, f\"Muito tempo com olhos fechados!\", (80, 435), cv2.FONT_HERSHEY_DUPLEX, 0.85, (58, 58, 55), 1)\n"
      ],
      "metadata": {
        "id": "dEadRDaLGqoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Verifique o tempo em que os olhos ficam fechados, alertando na tela se o tempo ultrapassar os limiares (1,5 segundos)."
      ],
      "metadata": {
        "id": "h-vrSf5TGyle"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 15. Exibição e finalização"
      ],
      "metadata": {
        "id": "tQ7NqYj6G05m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "        cv2.imshow('Camera', frame)\n",
        "        if cv2.waitKey(10) & 0xFF == ord('c'):\n",
        "            break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "-hM0Bs8TG2PW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Mostre o quadro na tela e verifique se a tecla 'c' foi pressionada para fechar a janela e liberar a câmera."
      ],
      "metadata": {
        "id": "JP6AUL6GG7u_"
      }
    }
  ]
}